{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, load_metric\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BATCH_SIZE = 16  # Batch size for training and evaluation\n",
    "EPOCHS = 3  # Number of training epochs\n",
    "LEARNING_RATE = 2e-5  # Learning rate for fine-tuning\n",
    "SEED = 42\n",
    "TASK_NAME = \"cola\"  # GLUE task name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()  # Clear GPU memory before starting\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GLUE dataset for task: cola...\n"
     ]
    }
   ],
   "source": [
    "# Load GLUE dataset\n",
    "print(f\"Loading GLUE dataset for task: {TASK_NAME}...\")\n",
    "dataset = load_dataset(\"glue\", TASK_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7c42ab02f6443ebb3e69a0cc0bad07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a285f6a44a50464fabf13c3b4df3a10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f422d452fa93417eaa9483241f78aaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set the format for PyTorch\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ALBERT model for sequence classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ALBERT model for sequence classification\n",
    "print(\"Loading ALBERT model for sequence classification...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farha\\AppData\\Local\\Temp\\ipykernel_20280\\887877820.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy_metric = load_metric(\"accuracy\")\n",
      "c:\\Users\\farha\\miniconda3\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\farha\\miniconda3\\Lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "f1_metric = load_metric(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    return {**accuracy, **f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Trainer...\n"
     ]
    }
   ],
   "source": [
    "# Initialize Trainer\n",
    "print(\"Initializing Trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f3b1b7fd5e40f28b08cd7a353706c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1605 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.628, 'grad_norm': 50.520591735839844, 'learning_rate': 1.9376947040498444e-05, 'epoch': 0.09}\n",
      "{'loss': 0.5896, 'grad_norm': 20.38228988647461, 'learning_rate': 1.8753894080996886e-05, 'epoch': 0.19}\n",
      "{'loss': 0.533, 'grad_norm': 59.33952713012695, 'learning_rate': 1.8130841121495328e-05, 'epoch': 0.28}\n",
      "{'loss': 0.5464, 'grad_norm': 29.85576629638672, 'learning_rate': 1.750778816199377e-05, 'epoch': 0.37}\n",
      "{'loss': 0.5238, 'grad_norm': 13.17466926574707, 'learning_rate': 1.688473520249221e-05, 'epoch': 0.47}\n",
      "{'loss': 0.5505, 'grad_norm': 19.437562942504883, 'learning_rate': 1.6261682242990654e-05, 'epoch': 0.56}\n",
      "{'loss': 0.5257, 'grad_norm': 11.828453063964844, 'learning_rate': 1.56386292834891e-05, 'epoch': 0.65}\n",
      "{'loss': 0.4726, 'grad_norm': 20.440431594848633, 'learning_rate': 1.501557632398754e-05, 'epoch': 0.75}\n",
      "{'loss': 0.4897, 'grad_norm': 20.19470977783203, 'learning_rate': 1.4392523364485981e-05, 'epoch': 0.84}\n",
      "{'loss': 0.4716, 'grad_norm': 19.275693893432617, 'learning_rate': 1.3769470404984425e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafb32f86d504eda9121780c49abc9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4816175401210785, 'eval_accuracy': 0.7718120805369127, 'eval_f1': 0.7444809174766884, 'eval_runtime': 3.4295, 'eval_samples_per_second': 304.126, 'eval_steps_per_second': 19.245, 'epoch': 1.0}\n",
      "{'loss': 0.4507, 'grad_norm': 21.48601531982422, 'learning_rate': 1.3146417445482867e-05, 'epoch': 1.03}\n",
      "{'loss': 0.3518, 'grad_norm': 29.2148494720459, 'learning_rate': 1.2523364485981309e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3355, 'grad_norm': 24.31055450439453, 'learning_rate': 1.1900311526479751e-05, 'epoch': 1.21}\n",
      "{'loss': 0.3653, 'grad_norm': 27.39017105102539, 'learning_rate': 1.1277258566978193e-05, 'epoch': 1.31}\n",
      "{'loss': 0.3366, 'grad_norm': 14.646661758422852, 'learning_rate': 1.0654205607476635e-05, 'epoch': 1.4}\n",
      "{'loss': 0.3748, 'grad_norm': 57.096580505371094, 'learning_rate': 1.0031152647975077e-05, 'epoch': 1.5}\n",
      "{'loss': 0.3293, 'grad_norm': 46.044864654541016, 'learning_rate': 9.40809968847352e-06, 'epoch': 1.59}\n",
      "{'loss': 0.3974, 'grad_norm': 14.311997413635254, 'learning_rate': 8.785046728971963e-06, 'epoch': 1.68}\n",
      "{'loss': 0.3068, 'grad_norm': 24.26105308532715, 'learning_rate': 8.161993769470406e-06, 'epoch': 1.78}\n",
      "{'loss': 0.309, 'grad_norm': 17.50522232055664, 'learning_rate': 7.538940809968847e-06, 'epoch': 1.87}\n",
      "{'loss': 0.3614, 'grad_norm': 25.37381935119629, 'learning_rate': 6.91588785046729e-06, 'epoch': 1.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bba326538e14e3ea1fd57346d7d5bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4479144811630249, 'eval_accuracy': 0.8024928092042186, 'eval_f1': 0.8016153026969809, 'eval_runtime': 3.3671, 'eval_samples_per_second': 309.759, 'eval_steps_per_second': 19.601, 'epoch': 2.0}\n",
      "{'loss': 0.2453, 'grad_norm': 3.437206268310547, 'learning_rate': 6.292834890965732e-06, 'epoch': 2.06}\n",
      "{'loss': 0.2376, 'grad_norm': 23.956539154052734, 'learning_rate': 5.669781931464174e-06, 'epoch': 2.15}\n",
      "{'loss': 0.1845, 'grad_norm': 48.463218688964844, 'learning_rate': 5.046728971962617e-06, 'epoch': 2.24}\n",
      "{'loss': 0.2583, 'grad_norm': 23.536489486694336, 'learning_rate': 4.42367601246106e-06, 'epoch': 2.34}\n",
      "{'loss': 0.2367, 'grad_norm': 25.13164520263672, 'learning_rate': 3.800623052959502e-06, 'epoch': 2.43}\n",
      "{'loss': 0.2226, 'grad_norm': 38.88330078125, 'learning_rate': 3.177570093457944e-06, 'epoch': 2.52}\n",
      "{'loss': 0.2043, 'grad_norm': 91.66117858886719, 'learning_rate': 2.5545171339563862e-06, 'epoch': 2.62}\n",
      "{'loss': 0.2181, 'grad_norm': 11.124504089355469, 'learning_rate': 1.9314641744548286e-06, 'epoch': 2.71}\n",
      "{'loss': 0.1942, 'grad_norm': 3.9439268112182617, 'learning_rate': 1.308411214953271e-06, 'epoch': 2.8}\n",
      "{'loss': 0.1787, 'grad_norm': 44.949092864990234, 'learning_rate': 6.853582554517134e-07, 'epoch': 2.9}\n",
      "{'loss': 0.1978, 'grad_norm': 73.2325210571289, 'learning_rate': 6.230529595015577e-08, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58722c75a13d465d9f65773aa8c68756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6106752753257751, 'eval_accuracy': 0.8216682646212847, 'eval_f1': 0.815845215820613, 'eval_runtime': 3.2714, 'eval_samples_per_second': 318.82, 'eval_steps_per_second': 20.175, 'epoch': 3.0}\n",
      "{'train_runtime': 239.3048, 'train_samples_per_second': 107.198, 'train_steps_per_second': 6.707, 'train_loss': 0.362840747573294, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1605, training_loss=0.362840747573294, metrics={'train_runtime': 239.3048, 'train_samples_per_second': 107.198, 'train_steps_per_second': 6.707, 'total_flos': 153264501112320.0, 'train_loss': 0.362840747573294, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "print(\"Starting fine-tuning...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fbc81ca7ff4af6b494e291a2534299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.4479144811630249, 'eval_accuracy': 0.8024928092042186, 'eval_f1': 0.8016153026969809, 'eval_runtime': 3.2727, 'eval_samples_per_second': 318.696, 'eval_steps_per_second': 20.167, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "print(\"Evaluating model on validation set...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the fine-tuned model...\n",
      "Fine-tuning complete and model saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "print(\"Saving the fine-tuned model...\")\n",
    "model.save_pretrained(\"./fine_tuned_albert\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_albert\")\n",
    "print(\"Fine-tuning complete and model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the results file\n",
    "results_file = \"./results.csv\"\n",
    "\n",
    "# Create a DataFrame with the task name and evaluation results\n",
    "new_results = pd.DataFrame({\"task\": [TASK_NAME], **eval_results})\n",
    "\n",
    "# Check if the results file already exists\n",
    "if os.path.exists(results_file):\n",
    "    # Read the existing results\n",
    "    existing_results = pd.read_csv(results_file)\n",
    "    # Append the new results\n",
    "    updated_results = pd.concat([existing_results, new_results], ignore_index=True)\n",
    "else:\n",
    "    # If the file doesn't exist, use the new results as the updated results\n",
    "    updated_results = new_results\n",
    "\n",
    "# Save the updated results to the CSV file\n",
    "updated_results.to_csv(results_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
